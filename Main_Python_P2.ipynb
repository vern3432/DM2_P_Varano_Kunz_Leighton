{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Results:\n",
      "Explained Variance Ratio:\n",
      "Component 1: 0.2723\n",
      "Component 2: 0.1423\n",
      "Component 3: 0.1309\n",
      "Component 4: 0.1088\n",
      "Component 5: 0.0872\n",
      "Component 6: 0.0748\n",
      "Component 7: 0.0659\n",
      "Component 8: 0.0588\n",
      "Component 9: 0.0228\n",
      "Component 10: 0.0171\n",
      "Component 11: 0.0117\n",
      "Component 12: 0.0068\n",
      "Component 13: 0.0006\n",
      "Component 14: 0.0001\n",
      "\n",
      "Cumulative Explained Variance:\n",
      "Up to Component 1: 0.2723\n",
      "Up to Component 2: 0.4146\n",
      "Up to Component 3: 0.5456\n",
      "Up to Component 4: 0.6543\n",
      "Up to Component 5: 0.7415\n",
      "Up to Component 6: 0.8163\n",
      "Up to Component 7: 0.8822\n",
      "Up to Component 8: 0.9410\n",
      "Up to Component 9: 0.9638\n",
      "Up to Component 10: 0.9809\n",
      "Up to Component 11: 0.9925\n",
      "Up to Component 12: 0.9994\n",
      "Up to Component 13: 0.9999\n",
      "Up to Component 14: 1.0000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[43  0  4]\n",
      " [ 0 55  5]\n",
      " [ 4  4 32]]\n",
      "\n",
      "F1 Score: 0.8848103615343845\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "bikesDf = pd.read_csv(\"day.csv\")\n",
    "\n",
    "X = bikesDf.drop(columns=['cnt', 'dteday'])  \n",
    "y = bikesDf['cnt']  # Target\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# PCA\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "cumulative_explained_variance = explained_variance_ratio.cumsum()\n",
    "\n",
    "rental_bins = pd.qcut(y, q=3, labels=['low', 'medium', 'high'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, rental_bins, test_size=0.2, random_state=42)\n",
    "\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"PCA Results:\")\n",
    "print(\"Explained Variance Ratio:\")\n",
    "for i, ratio in enumerate(explained_variance_ratio):\n",
    "    print(f\"Component {i+1}: {ratio:.4f}\")\n",
    "\n",
    "print(\"\\nCumulative Explained Variance:\")\n",
    "for i, cm_ratio in enumerate(cumulative_explained_variance):\n",
    "    print(f\"Up to Component {i+1}: {cm_ratio:.4f}\")\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nF1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          instant      season          yr        mnth     holiday     weekday   \n",
      "count  731.000000  731.000000  731.000000  731.000000  731.000000  731.000000  \\\n",
      "mean   366.000000    2.496580    0.500684    6.519836    0.028728    2.997264   \n",
      "std    211.165812    1.110807    0.500342    3.451913    0.167155    2.004787   \n",
      "min      1.000000    1.000000    0.000000    1.000000    0.000000    0.000000   \n",
      "25%    183.500000    2.000000    0.000000    4.000000    0.000000    1.000000   \n",
      "50%    366.000000    3.000000    1.000000    7.000000    0.000000    3.000000   \n",
      "75%    548.500000    3.000000    1.000000   10.000000    0.000000    5.000000   \n",
      "max    731.000000    4.000000    1.000000   12.000000    1.000000    6.000000   \n",
      "\n",
      "       workingday  weathersit        temp       atemp         hum   windspeed   \n",
      "count  731.000000  731.000000  731.000000  731.000000  731.000000  731.000000  \\\n",
      "mean     0.683995    1.395349    0.495385    0.474354    0.627894    0.190486   \n",
      "std      0.465233    0.544894    0.183051    0.162961    0.142429    0.077498   \n",
      "min      0.000000    1.000000    0.059130    0.079070    0.000000    0.022392   \n",
      "25%      0.000000    1.000000    0.337083    0.337842    0.520000    0.134950   \n",
      "50%      1.000000    1.000000    0.498333    0.486733    0.626667    0.180975   \n",
      "75%      1.000000    2.000000    0.655417    0.608602    0.730209    0.233214   \n",
      "max      1.000000    3.000000    0.861667    0.840896    0.972500    0.507463   \n",
      "\n",
      "            casual   registered          cnt  \n",
      "count   731.000000   731.000000   731.000000  \n",
      "mean    848.176471  3656.172367  4504.348837  \n",
      "std     686.622488  1560.256377  1937.211452  \n",
      "min       2.000000    20.000000    22.000000  \n",
      "25%     315.500000  2497.000000  3152.000000  \n",
      "50%     713.000000  3662.000000  4548.000000  \n",
      "75%    1096.000000  4776.500000  5956.000000  \n",
      "max    3410.000000  6946.000000  8714.000000  \n",
      "['instant', 'dteday', 'season', 'yr', 'mnth', 'holiday', 'weekday', 'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed', 'casual', 'registered', 'cnt']\n"
     ]
    }
   ],
   "source": [
    "print(bikesDf.describe())\n",
    "print(bikesDf.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PCA + SVM Results:\n",
      "\n",
      "Confusion Matrix:\n",
      "[[43  0  4]\n",
      " [ 0 54  6]\n",
      " [ 4  4 32]]\n",
      "\n",
      "F1 Score: 0.8784677988599325\n"
     ]
    }
   ],
   "source": [
    "# Perform PCA before splitting the data\n",
    "pca = PCA(n_components=10)  # Choose the number of components\n",
    "X_pca_train = pca.fit_transform(X_train)\n",
    "X_pca_test = pca.transform(X_test)\n",
    "\n",
    "# Train SVM on the PCA-transformed training data\n",
    "svm = SVC()\n",
    "svm.fit(X_pca_train, y_train)\n",
    "\n",
    "# Predict labels for the transformed test data\n",
    "y_pred = svm.predict(X_pca_test)\n",
    "\n",
    "# Evaluate the performance of the classifier\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"\\nPCA + SVM Results:\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nF1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'C': 100, 'gamma': 0.01}\n",
      "Best Score: 0.9331859711170056\n",
      "\n",
      "PCA + Optimized SVM Results:\n",
      "\n",
      "Confusion Matrix:\n",
      "[[46  0  1]\n",
      " [ 0 56  4]\n",
      " [ 3  1 36]]\n",
      "\n",
      "F1 Score: 0.9390008140008143\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [0.01, 0.1, 1, 10]}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_pca_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)\n",
    "\n",
    "# Predict labels for the test data using the best estimator\n",
    "best_estimator = grid_search.best_estimator_\n",
    "y_pred = best_estimator.predict(X_pca_test)\n",
    "\n",
    "# Evaluate the performance of the classifier\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"\\nPCA + Optimized SVM Results:\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nF1 Score:\", f1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
